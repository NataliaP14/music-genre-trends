{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ccc9e2",
   "metadata": {},
   "source": [
    "# Genre Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608bf18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a8296",
   "metadata": {},
   "source": [
    "### Merge Spotify Features & Lyrical dataset & Cleaning spotify genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9333c487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped_genres\n",
      "Rock           10365\n",
      "Pop             7146\n",
      "Rap             2472\n",
      "Hip Hop         1687\n",
      "Metal           1675\n",
      "Country          775\n",
      "Soul             756\n",
      "R&B              641\n",
      "Folk             574\n",
      "Electronic       428\n",
      "Alternative      245\n",
      "Jazz             221\n",
      "Funk             203\n",
      "Disco            135\n",
      "Dance            114\n",
      "Blues            104\n",
      "Motown            30\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['title', 'artist', 'year', 'danceability', 'energy', 'loudness',\n",
       "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'emotions_scores', 'mapped_genres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as stats\n",
    "features_lyrics = pd.read_csv('../data/compressed/lyrics_spotify_features.csv')\n",
    "\n",
    "song_emotions = pd.read_csv('../data/compressed/songs_emotions.csv')\n",
    "\n",
    "features_lyrics = features_lyrics.merge(song_emotions, on= ['title', 'artist'], how='left')\n",
    "features_lyrics.drop(columns=['lyrics'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "new_genres =  [\"Alternative\", \"Blues\", \"Country\", \"Dance\", \"Disco\", \"EDM\", \"Electronic\", \"Folk\", \"Funk\",\n",
    "                  \"Hip Hop\", \"House\", \"Indie\", \"Jazz\", \"Metal\", \"Motown\", \"Pop\", \"R&B\", \"Rap\", \"Rock\", \"Soul\"]\n",
    "\n",
    "ng_map = {g.lower(): g for g in new_genres}\n",
    "\n",
    "genius_map = {'rb': 'R&B',\n",
    "              'rock': 'Rock',\n",
    "              'pop': 'Pop',\n",
    "              'rap': 'Rap',}\n",
    "\n",
    "\n",
    "merge_map = {\"EDM\": \"Electronic\",\n",
    "             \"House\": \"Electronic\",\n",
    "             \"Indie\": \"Alternative\"}\n",
    "\n",
    "special_genres = [\"Hip Hop\", \"R&B\", \"Motown\"]\n",
    "\n",
    "def get_main_genre(genre, genius_genre):\n",
    "    if not genre or not isinstance(genre, str):\n",
    "        \n",
    "    \n",
    "        if genius_genre:\n",
    "            return genius_map.get(genius_genre.lower(), genius_genre.title())\n",
    "        else:\n",
    "            return \"\"\n",
    "    cleaned = genre.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "\n",
    "    genres = [genre.strip() for genre in cleaned.split(',') if genre.strip() != '']\n",
    "  \n",
    "\n",
    "    genres_list = []\n",
    "\n",
    "    for genre in genres:\n",
    "        genre_clean = genre.replace(\"_\", \" \").strip()\n",
    "        if genre_clean == \"\":\n",
    "            continue\n",
    "        \n",
    "        base_genre = None\n",
    "        for special in special_genres:\n",
    "            if special.lower() in genre_clean.lower():\n",
    "                base_genre = special\n",
    "                break\n",
    "            \n",
    "        if base_genre is None:\n",
    "            last = genre_clean.split()[-1].lower()\n",
    "            base_genre = ng_map.get(last, None)\n",
    "            \n",
    "                \n",
    "        if base_genre in merge_map:\n",
    "            base_genre = merge_map[base_genre]\n",
    "\n",
    "\n",
    "        if base_genre is not None:\n",
    "            genres_list.append(base_genre)\n",
    "\n",
    "        \n",
    "    if genres_list:\n",
    "        final_genres = stats.mode(genres_list) # returns most common genre in a list per song\n",
    "    else:\n",
    "        if genius_genre:\n",
    "            final_genres = genius_map.get(genius_genre.lower(), genius_genre.title())\n",
    "     \n",
    "\n",
    "    return final_genres\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features_lyrics['mapped_genres'] = features_lyrics.apply(lambda x: get_main_genre(x['spotify_genre_list'], x['genius_genre']), axis=1)\n",
    "features_lyrics = features_lyrics[features_lyrics['mapped_genres'] != 'Misc']\n",
    "\n",
    "features_lyrics.drop(columns=['spotify_genre_list', 'genius_genre', 'top_emotion', 'topEmotionWord'], inplace=True)\n",
    "\n",
    "print(features_lyrics['mapped_genres'].value_counts())\n",
    "features_lyrics.head()\n",
    "features_lyrics.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6be7c7",
   "metadata": {},
   "source": [
    "## K-means Clustering Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b15f7",
   "metadata": {},
   "source": [
    "### Preparing Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98bf3a9",
   "metadata": {},
   "source": [
    "#### Converting emotion_scores into Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72c8b601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>joy</th>\n",
       "      <th>positive</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, artist, year, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, emotions_scores, mapped_genres, positivity, anticipation, joy, positive, surprise, trust, anger, disgust, fear, negative, sadness, cluster]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "def convert_dictionary(x):\n",
    "    if isinstance(x,str):\n",
    "        return ast.literal_eval(x)\n",
    "    return x\n",
    "features_lyrics['emotions_scores'] = features_lyrics['emotions_scores'].apply(lambda x : convert_dictionary(x))\n",
    "features_lyrics['positivity'] = features_lyrics['emotions_scores'].apply(lambda x: x.get('positive') if isinstance(x, dict) else 0)\n",
    "features_lyrics[features_lyrics['positivity'] == np.nan]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012a9e1",
   "metadata": {},
   "source": [
    "#### Fetching Top Sentiment & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df883d",
   "metadata": {},
   "source": [
    "#### Fetching Emotion Scores & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ebc6a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anticipation</th>\n",
       "      <th>joy</th>\n",
       "      <th>positive</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27615</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27616</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27617</th>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27618</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27619</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anticipation   joy  positive  surprise  trust  anger  disgust  fear  \\\n",
       "0              12.0   9.0      29.0       8.0   17.0   12.0      9.0  12.0   \n",
       "1              36.0  40.0      44.0      34.0   36.0   39.0     13.0  12.0   \n",
       "2              10.0   4.0      16.0      11.0   11.0   11.0     12.0  19.0   \n",
       "3              30.0  25.0      37.0      21.0   20.0   27.0      9.0  14.0   \n",
       "4               8.0  19.0      28.0       4.0   10.0   23.0     13.0  12.0   \n",
       "...             ...   ...       ...       ...    ...    ...      ...   ...   \n",
       "27615           6.0   5.0       6.0       2.0    5.0    2.0      1.0   2.0   \n",
       "27616          15.0   4.0       8.0       7.0   20.0    4.0      2.0   3.0   \n",
       "27617          16.0  12.0      24.0       5.0   19.0   20.0     14.0  23.0   \n",
       "27618           2.0   3.0       4.0       1.0    3.0    0.0      0.0   0.0   \n",
       "27619           2.0   3.0       7.0       0.0    3.0    1.0      0.0   2.0   \n",
       "\n",
       "       negative  sadness  \n",
       "0          22.0     10.0  \n",
       "1          22.0     10.0  \n",
       "2          32.0     22.0  \n",
       "3          26.0      9.0  \n",
       "4          26.0      7.0  \n",
       "...         ...      ...  \n",
       "27615       7.0      4.0  \n",
       "27616       6.0      1.0  \n",
       "27617      35.0     22.0  \n",
       "27618       1.0      1.0  \n",
       "27619       4.0      2.0  \n",
       "\n",
       "[27571 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracts emotion scores and stores them in separate columns\n",
    "emotion_df = pd.json_normalize(features_lyrics['emotions_scores'])\n",
    "emotion_df = emotion_df.fillna(0.0)\n",
    "emotion_df.index = features_lyrics.index\n",
    "features_lyrics = pd.concat([features_lyrics, emotion_df], axis=1)\n",
    "features_lyrics.columns\n",
    "features_lyrics[emotion_df.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c6f59",
   "metadata": {},
   "source": [
    "### Spotify Feature Clusters For Each Genre, Top Sentiment and Top Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "spotify_features_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'anticipation', 'joy', 'surprise', 'trust', 'anger', 'disgust', 'fear', 'sadness', 'positive']\n",
    "\n",
    "clusters = 2\n",
    "for genre, songs_in_genre, in features_lyrics.groupby('mapped_genres'): # for each genre\n",
    "\n",
    "    samples = len(songs_in_genre)\n",
    "    if samples == 0: continue\n",
    "\n",
    "    k = min(clusters, samples)\n",
    "\n",
    "    spotify_features = songs_in_genre[spotify_features_list]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    spotify_features_scaled = scaler.fit_transform(spotify_features)\n",
    "\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 42)\n",
    "    label = kmeans.fit_predict(spotify_features_scaled)\n",
    "            \n",
    "\n",
    "    cluster_names = [f\"{genre}_cluster_{i+1}\" for i in label]\n",
    "\n",
    "    features_lyrics.loc[songs_in_genre.index, 'cluster'] = cluster_names\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d37da",
   "metadata": {},
   "source": [
    "### Analyzing & Classifying The Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da8dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters 17\n",
      "['Rap_cluster_1' 'Hip Hop_cluster_1' 'Pop_cluster_1'\n",
      " 'Electronic_cluster_1' 'Rock_cluster_1' 'Soul_cluster_1'\n",
      " 'Metal_cluster_1' 'Country_cluster_1' 'Folk_cluster_1' 'Funk_cluster_1'\n",
      " 'Disco_cluster_1' 'Blues_cluster_1' 'R&B_cluster_1' 'Dance_cluster_1'\n",
      " 'Alternative_cluster_1' 'Jazz_cluster_1' 'Motown_cluster_1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Clusters\", features_lyrics['cluster'].unique().size)\n",
    "print(features_lyrics['cluster'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e6d7008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       danceability    energy  loudness  speechiness  \\\n",
      "cluster                                                                \n",
      "Alternative_cluster_1      0.399957  0.512283  0.669760     0.061229   \n",
      "Blues_cluster_1            0.485022  0.297595  0.424557     0.057300   \n",
      "Country_cluster_1          0.502865  0.492329  0.689505     0.000000   \n",
      "Dance_cluster_1            0.709181  0.878137  0.979059     0.122157   \n",
      "Disco_cluster_1            0.685475  0.387161  0.280511     0.010888   \n",
      "Electronic_cluster_1       0.755914  0.726003  0.893142     0.178511   \n",
      "Folk_cluster_1             0.341219  0.000000  0.000000     0.010892   \n",
      "Funk_cluster_1             0.755244  0.418481  0.255019     0.205560   \n",
      "Hip Hop_cluster_1          1.000000  0.602865  0.761778     1.000000   \n",
      "Jazz_cluster_1             0.372710  0.047023  0.116960     0.096831   \n",
      "Metal_cluster_1            0.000000  1.000000  1.000000     0.228937   \n",
      "Motown_cluster_1           0.676659  0.401193  0.417231     0.009008   \n",
      "Pop_cluster_1              0.562430  0.475062  0.686650     0.114367   \n",
      "R&B_cluster_1              0.764749  0.336243  0.601435     0.257044   \n",
      "Rap_cluster_1              0.949553  0.580991  0.818026     0.812003   \n",
      "Rock_cluster_1             0.254002  0.604593  0.609687     0.061325   \n",
      "Soul_cluster_1             0.645299  0.337021  0.458849     0.101187   \n",
      "\n",
      "                       acousticness  instrumentalness  liveness   valence  \\\n",
      "cluster                                                                     \n",
      "Alternative_cluster_1      0.444760          0.782677  0.116362  0.247413   \n",
      "Blues_cluster_1            0.700732          0.200173  0.608418  0.656831   \n",
      "Country_cluster_1          0.469088          0.000000  0.367496  0.525234   \n",
      "Dance_cluster_1            0.110880          0.951376  0.693680  0.448386   \n",
      "Disco_cluster_1            0.406546          0.203631  0.700271  0.745235   \n",
      "Electronic_cluster_1       0.171653          0.595181  0.386497  0.244470   \n",
      "Folk_cluster_1             1.000000          0.540511  0.200978  0.246104   \n",
      "Funk_cluster_1             0.410960          0.385435  0.483223  0.835670   \n",
      "Hip Hop_cluster_1          0.229834          0.069214  0.787542  0.586201   \n",
      "Jazz_cluster_1             0.955067          0.787918  0.625073  0.239036   \n",
      "Metal_cluster_1            0.000000          1.000000  0.792659  0.000000   \n",
      "Motown_cluster_1           0.694616          0.314493  1.000000  1.000000   \n",
      "Pop_cluster_1              0.431352          0.267247  0.262187  0.363688   \n",
      "R&B_cluster_1              0.426672          0.079014  0.000000  0.406480   \n",
      "Rap_cluster_1              0.235769          0.077940  0.590108  0.399614   \n",
      "Rock_cluster_1             0.294696          0.725062  0.686468  0.384725   \n",
      "Soul_cluster_1             0.574618          0.208811  0.059233  0.611762   \n",
      "\n",
      "                          tempo  anticipation       joy  surprise     trust  \\\n",
      "cluster                                                                       \n",
      "Alternative_cluster_1  0.708121      0.000000  0.041034  0.000000  0.075721   \n",
      "Blues_cluster_1        0.137208      0.032510  0.184147  0.125256  0.026608   \n",
      "Country_cluster_1      0.426387      0.256122  0.256650  0.315204  0.268028   \n",
      "Dance_cluster_1        1.000000      0.118891  0.298374  0.265257  0.277451   \n",
      "Disco_cluster_1        0.131201      0.402293  0.706609  0.467448  0.449855   \n",
      "Electronic_cluster_1   0.604598      0.211605  0.345091  0.332981  0.221082   \n",
      "Folk_cluster_1         0.249549      0.076432  0.147906  0.057976  0.138257   \n",
      "Funk_cluster_1         0.053132      0.496694  0.852273  0.496840  0.552532   \n",
      "Hip Hop_cluster_1      0.039265      1.000000  0.560998  1.000000  1.000000   \n",
      "Jazz_cluster_1         0.000000      0.000857  0.119394  0.060903  0.000000   \n",
      "Metal_cluster_1        0.824049      0.132326  0.000000  0.141140  0.179606   \n",
      "Motown_cluster_1       0.602614      0.008917  1.000000  0.364039  0.405935   \n",
      "Pop_cluster_1          0.334473      0.217856  0.393397  0.293952  0.262445   \n",
      "R&B_cluster_1          0.054758      0.304759  0.713147  0.334299  0.489402   \n",
      "Rap_cluster_1          0.256596      0.840550  0.507490  0.898819  0.808513   \n",
      "Rock_cluster_1         0.627850      0.063963  0.111640  0.119698  0.102017   \n",
      "Soul_cluster_1         0.131775      0.322444  0.711889  0.293069  0.303098   \n",
      "\n",
      "                          anger   disgust      fear   sadness  positive  \n",
      "cluster                                                                  \n",
      "Alternative_cluster_1  0.096999  0.156223  0.208836  0.143087  0.000000  \n",
      "Blues_cluster_1        0.144311  0.165102  0.306672  0.178829  0.073380  \n",
      "Country_cluster_1      0.136534  0.159427  0.216709  0.237238  0.207663  \n",
      "Dance_cluster_1        0.112929  0.188560  0.152232  0.115157  0.310769  \n",
      "Disco_cluster_1        0.164411  0.131481  0.203459  0.186494  0.599145  \n",
      "Electronic_cluster_1   0.187037  0.228487  0.311151  0.296464  0.280449  \n",
      "Folk_cluster_1         0.085332  0.112163  0.161402  0.142614  0.123293  \n",
      "Funk_cluster_1         0.148619  0.201932  0.209221  0.303523  0.829735  \n",
      "Hip Hop_cluster_1      1.000000  1.000000  1.000000  1.000000  0.972611  \n",
      "Jazz_cluster_1         0.000000  0.063182  0.000000  0.000000  0.018879  \n",
      "Metal_cluster_1        0.428216  0.438594  0.643133  0.612028  0.035125  \n",
      "Motown_cluster_1       0.072995  0.000000  0.057590  0.165445  1.000000  \n",
      "Pop_cluster_1          0.164030  0.206325  0.287354  0.317238  0.344519  \n",
      "R&B_cluster_1          0.190300  0.214857  0.318417  0.352039  0.729148  \n",
      "Rap_cluster_1          0.928074  0.941764  0.933752  0.982619  0.786497  \n",
      "Rock_cluster_1         0.137934  0.176281  0.228810  0.197414  0.053983  \n",
      "Soul_cluster_1         0.116671  0.144824  0.215765  0.252127  0.609274  \n"
     ]
    }
   ],
   "source": [
    "cluster_avgs = features_lyrics.groupby('cluster')[spotify_features_list].mean()\n",
    "cluster_avgs = (cluster_avgs - cluster_avgs.min()) / (cluster_avgs.max() - cluster_avgs.min())\n",
    "print(cluster_avgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c54fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "Rock_cluster_1           10365\n",
      "Pop_cluster_1             7146\n",
      "Rap_cluster_1             2472\n",
      "Hip Hop_cluster_1         1687\n",
      "Metal_cluster_1           1675\n",
      "Country_cluster_1          775\n",
      "Soul_cluster_1             756\n",
      "R&B_cluster_1              641\n",
      "Folk_cluster_1             574\n",
      "Electronic_cluster_1       428\n",
      "Alternative_cluster_1      245\n",
      "Jazz_cluster_1             221\n",
      "Funk_cluster_1             203\n",
      "Disco_cluster_1            135\n",
      "Dance_cluster_1            114\n",
      "Blues_cluster_1            104\n",
      "Motown_cluster_1            30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(features_lyrics['cluster'].value_counts())\n",
    "features_lyrics.head(10)\n",
    "\n",
    "features_lyrics.to_csv('../data/processed/lyrics_features_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48964470",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = features_lyrics.groupby(['cluster', 'year']).size().reset_index(name='count')\n",
    "\n",
    "table = group.pivot_table(index='year', columns='cluster', values='count', fill_value=0)\n",
    "\n",
    "with open('../data/processed/clusters.txt', 'w') as f:\n",
    "    f.write(table.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3d10c",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b295fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
